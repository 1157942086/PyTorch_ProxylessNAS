data:
  search:
    # split: False # split training data into train/val set
    # sp_ratio: 0.5 # split ratio
    train: './data/ILSVRC2012' # path to train data (ImageNet)
    val: '' # path to validation data (ImageNet)
    type: 'CIFAR10'
    # type: 'MNIST'
    # type: 'ImageNet'
  augment:
    split: False
    train: ''
    val: ''
    type: 'CIFAR10'
    # type: 'MNIST'
    # type: 'ImageNet'
---
train:
  split: True
  w_data_ratio: 0.5
  trn_batch_size: 64
  val_batch_size: 64
  workers: 4
  w_optim:
    type: 'sgd'
    lr: 0.025
    lr_min: 0.001
    momentum: 0.9
    weight_decay: 0.0003
    nesterov: True
    # type: 'adabound'
    # lr: 0.001
    # final_lr: 0.05
  a_optim:
    type: 'adam'
    lr: 0.0003
    betas:
     - 0.5
     - 0.999
    momentum: 0.9
    weight_decay: 0.001
  aux_weight: 0.4
  w_grad_clip: 5.
  warmup_epochs: 0
  epochs: 50
  print_freq: 200
  save_freq: 10
  plot: False
  plot_path: './searchs'
---
valid:
  trn_batch_size: 96
  val_batch_size: 96
  workers: 4
  w_optim:
    type: 'sgd'
    lr: 0.025
    lr_min: 0.001
    momentum: 0.9
    weight_decay: 0.0003
    nesterov: True
  aux_weight: 0.4
  drop_path_prob: 0.2
  w_grad_clip: 5.
  genotype: ''
  gt_file: ''
  epochs: 600
  print_freq: 200
  save_freq: 50
---
model:
  type: 'darts'
  classes: 10             # use 10 for MNIST, CIFAR10
  channel_in: 3           # 3 for ImageNet/CIFAR10, 1 for MNIST
  channel_init: 16        # init channel
  channel_multiplier: 3   # init channel multiplier
  nodes: 4                # num of nodes (states) per layer
  layers: 20              # num of DAG layers (cells) in model
  inputs_model: 1
  inputs_layer: 2
  inputs_node: 1
  auxiliary: True
  sepconv_stack: True
  w_latency: 0.0
  verbose: False
---
genotypes:
  - 'max_pool_3x3'
  - 'avg_pool_3x3'
  - 'skip_connect' # identity
  - 'sep_conv_3x3'
  - 'sep_conv_5x5'
  - 'dil_conv_3x3'
  - 'dil_conv_5x5'
  # - 'sep_conv_7x7',
  - 'none'
---
log:
  chkpt_dir: 'chkpt'
  log_dir: 'logs'
---
device:
  gpus: 'all'
  seed: 2
